{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# !pip install mip\n",
    "from mip import Model, xsum, BINARY, minimize,CONTINUOUS, CBC, ConstrsGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regobj(x, y, s, gamma, k):\n",
    "#   print('check', s[0] == 1)\n",
    "  indices = [i for i in range(len(s)) if s[i] >= 0.5] #getting the indices of the currently chosen binary variables\n",
    "  n = y.shape[0] #getting the number of observations in y\n",
    "  denom = 2 * n #simplifying computations for later\n",
    "#   print('\\ncur indices', indices)\n",
    "#   print('here s', s)\n",
    "  Xs = x[:, indices] #only keeping x features that are chosen from the binary constraints\n",
    "  \n",
    "  #finding the akpha value for ease of later computation as well\n",
    "#   print('x', x.shape)\n",
    "#   print('xs', Xs.shape)\n",
    "#   xt = np.transpose(Xs)\n",
    "#   x_x = np.matmul(xt, Xs)\n",
    "#   ident = np.identity(len(indices)) / gamma\n",
    "# #   print('ident', ident.shape)\n",
    "# #   print('x x', x_x.shape)\n",
    "#   together = ident + x_x\n",
    "#   inverse = np.linalg.inv(together)\n",
    "#   x_y = np.matmul(xt, y)\n",
    "# #   print('inverse', inverse.shape)\n",
    "# #   print('x y ', x_y.shape)\n",
    "#   first_mult = np.matmul(inverse, x_y)\n",
    "#   second_mult = np.matmul(Xs, first_mult)\n",
    "#   alpha = y - second_mult\n",
    "  \n",
    "  alpha = y - np.matmul(Xs, \\\n",
    "                        np.matmul(np.linalg.inv(np.identity(len(indices)) / gamma + np.matmul(np.transpose(Xs), Xs)),\\\n",
    "                                  np.matmul(np.transpose(Xs), y)))\n",
    "\n",
    "  #finding the current objective function value\n",
    "  obj_val = (np.dot(np.transpose(y), alpha)) / denom\n",
    "  \n",
    "  #finding the current gradient\n",
    "  tmp = np.matmul(np.transpose(x), alpha)\n",
    "  gradient = -1 * gamma * np.square(tmp) / denom\n",
    "  \n",
    "  return obj_val, list(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SparseRegression(x, y, gamma, k):\n",
    "  p = x.shape[1] #p is our number of total coefficients\n",
    "  \n",
    "  #defining our model to optimize with\n",
    "  model = Model(solver_name=CBC)\n",
    "  \n",
    "  #defining the variables for our model\n",
    "  s = [model.add_var(var_type=BINARY, name='s({})'.format(j)) for j in range(p)] #binary determing if coefficient is 0\n",
    "  t = model.add_var(var_type=CONTINUOUS, name='t', lb=0) #variable approximate the value of our inner objective function, increases with each cutting plane cut\n",
    "  \n",
    "  #defining the objective function\n",
    "  model.objective = minimize(t)\n",
    "  \n",
    "  #adding constraints to our model\n",
    "  model += xsum(s) <= k #sparsity constraint on our binary variables\n",
    "\n",
    "  #calculating the taylor series approximation and resulting first cut\n",
    "  s0 = [1] * k + [0] * (p - k) #initialize starting point\n",
    "  \n",
    "  #looking at the current points objective value and gradient with respect to the variables\n",
    "  obj_val, gradient = regobj(x, y, s0, gamma, k)\n",
    "  \n",
    "  #adding our first cut\n",
    "  model += t >= obj_val + xsum(gradient[i] * (s[i] - s0[i]) for i in range(p))\n",
    "  \n",
    "#   print('s_val', s0)\n",
    "#   print('obj', obj_val)\n",
    "#   print('gradient', gradient)\n",
    "  \n",
    "  #defining a class for the outer approximation of the function which will add lazy constraints\n",
    "  class outer_approximation(ConstrsGenerator):\n",
    "    \n",
    "    #initializing our class\n",
    "    def __init__(self, s, t, x, y, p, k, gamma):\n",
    "      #initialing the decision variables\n",
    "      self.s, self.t = s, t\n",
    "      \n",
    "      #initializing the parameters\n",
    "      self.x, self.y, self.p, self.k, self.gamma = x, y, p, k, gamma\n",
    "\n",
    "    #adding the lazy constraint\n",
    "    def generate_constrs(self, model: Model, depth: int = 0, npass: int = 0):\n",
    "      #getting the current objective value and gradient\n",
    "      cur_s = model.translate(self.s)\n",
    "      cur_t = model.translate(self.t)\n",
    "#       print('intial cur s', cur_s)\n",
    "      cur_values = [cur_s[i].x for i in range(self.p)]\n",
    "#       print('indexed cur s', cur_values)\n",
    "#       print(\"entering with x\", self.x.shape, 'y', self.y.shape, 'k', self.k, 'gamma', self.gamma)\n",
    "      obj_val, gradient = regobj(self.x, self.y, cur_values, gamma, self.k)\n",
    "#       print('s_val', cur_values)\n",
    "#       print('obj', obj_val)\n",
    "#       print('gradient', gradient)\n",
    "      t_val = model.translate(self.t)\n",
    "#       print('t value', t_val.x)\n",
    "      #adding our lazy constraint\n",
    "#       print('try to multiple', [cur_values[i] * gradient[i] for i in range(p)])\n",
    "#       print('all their types')\n",
    "      offset = 0\n",
    "      for i in range(len(cur_values)):\n",
    "        offset += cur_values[i] * gradient[i]\n",
    "#       print('offset', offset)\n",
    "#       print('gradient', gradient)\n",
    "#       print('obj val', obj_val)\n",
    "#       print('cur_s', cur_s)\n",
    "      model += cur_t >= obj_val + xsum(gradient[i] * cur_s[i] for i in range(p)) - offset\n",
    "#       print('model has {} vars, {} constraints and {} nzs'.format(model.num_cols, model.num_rows, model.num_nz))\n",
    "#       print('added a lazy constraint')\n",
    "      return \n",
    "  \n",
    "  #adding the lazy constraint generator to our model\n",
    "#   model.cuts_generator = outer_approximation(s, t, x, y, p, k, gamma)\n",
    "  model.lazy_constrs_generator = outer_approximation(s, t, x, y, p, k, gamma)\n",
    "  \n",
    "  #adding our initial feasible solution\n",
    "  model.start = [(s[j], 1) for j in range(k)] + [(s[j], 0) for j in range(k,p)]\n",
    "  \n",
    "  #solving the model\n",
    "  print(\"Starting the model\")\n",
    "  status = model.optimize()\n",
    "  print(status)\n",
    "#   print('model has {} vars, {} constraints and {} nzs'.format(model.num_cols, model.num_rows, model.num_nz))\n",
    "  \n",
    "  #returning the beta coefficients for this it\n",
    "  s_opt = []\n",
    "  for j in range(p):\n",
    "    s_opt.append(s[j].x)\n",
    "  \n",
    "  #deriving the actual beta values of this solution\n",
    "  indices = [i for i in range(len(s_opt)) if s_opt[i] >= 0.5] #getting the indices of the currently chosen binary variables\n",
    "  Xs = x[:, indices] #only keeping x features that are chosen from the binary constraints\n",
    "#   print('xs shape', Xs.shape)\n",
    "  xt = np.transpose(Xs)\n",
    "#   print('xt shape', xt.shape)\n",
    "  ident = np.identity(len(indices)) / gamma\n",
    "#   print('ident', ident.shape)\n",
    "  inner_add = ident + np.matmul(xt, Xs)\n",
    "#   print('inner_add', inner_add.shape)\n",
    "  x_y = np.matmul(xt, y)\n",
    "#   print('x y ', x_y.shape)\n",
    "  inner_division = np.matmul(np.linalg.inv(inner_add), x_y)\n",
    "#   print('inner_division', inner_division.shape)\n",
    "  x_thing = np.matmul(Xs, inner_division)\n",
    "#   print('x_thing', x_thing.shape)\n",
    "  subtract_inner = y - x_thing\n",
    "#   print('subtract inner', subtract_inner.shape)\n",
    "  beta_values = np.matmul(gamma * xt, subtract_inner)\n",
    "  final_betas = [0] * p\n",
    "  i = 0\n",
    "  for indx in indices:\n",
    "    final_betas[indx] = beta_values[i]\n",
    "    i += 1\n",
    "    \n",
    "  return s_opt, [1 if x > 0.5 else 0 for x in s_opt], final_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0      1     2     3      4     5     6\n",
      "0  6.4673  225.1  78.2  55.0  29.47  1.26  47.9\n",
      "1  9.4293  242.4  65.5  66.1  28.51  0.76  23.4\n",
      "2  9.4986  242.4  70.7  67.7  28.64  0.70  48.4\n",
      "3  9.4760  257.1  67.3  68.2  29.08  0.77  37.3\n",
      "4  7.6488  238.1  71.7  57.2  27.58  0.95  38.6\n",
      "5  7.3895  261.1  60.9  62.3  29.34  1.02  33.9\n",
      "6  9.1652  261.1  68.7  65.3  28.14  1.14  40.2\n",
      "7  7.4426  252.0  70.7  62.3  29.67  1.16  39.7\n",
      "8  7.3775  238.2  65.3  61.4  30.04  1.05  36.2\n",
      "9  7.8969  251.0  67.4  63.0  28.83  0.83  34.5\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Train lpga2008_opt.csv\", header=None)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 6)\n",
      "(78,)\n"
     ]
    }
   ],
   "source": [
    "x_train = df.to_numpy()[:,1:]\n",
    "y_train = df.loc[:, 0].to_numpy()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the model\n",
      "OptimizationStatus.OPTIMAL\n"
     ]
    }
   ],
   "source": [
    "s, indx, betas = SparseRegression(x_train, y_train, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 1.0, 1.0, 0.0, 1.0]\n",
      "[0, 0, 1, 1, 0, 1]\n",
      "[0, 0, 0.2374568251083531, -0.2883098152283381, 0, 0.036401490485136634]\n"
     ]
    }
   ],
   "source": [
    "print(s)\n",
    "print(indx)\n",
    "print(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 1.0, 1.0, 0.0, 1.0]\n",
      "[0, 0, 1, 1, 0, 1]\n",
      "[0, 0, 0.2374568251083531, -0.2883098152283381, 0, 0.036401490485136634]\n"
     ]
    }
   ],
   "source": [
    "print(s)\n",
    "print(indx)\n",
    "print(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
